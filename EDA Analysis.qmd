This is a new Quarto Markdown file for EDA on Larger Data Set


```{python}
import pandas as pd
import altair as alt

CA_ACLED = pd.read_csv('/Users/willsigal/Desktop/UChicago/Fall 2025/Python Final/acled_project_data_cleaned.csv')
```


```{python}
required_columns = ['year', 'event_type', 'location']
if not all(col in CA_ACLED.columns for col in required_columns):
    raise ValueError(f"The dataset must include the columns: {', '.join(required_columns)}")

```

## Bar Chart for total Crimes per Year

```{python}
CA_ACLED['year'] = CA_ACLED['year'].astype(int)
CA_ACLED.dropna(subset=['event_type'], inplace=True)
CA_ACLED = CA_ACLED[CA_ACLED['country'] != 'Mexico']
# Aggregate data to get total crimes per year per country
aggregated_data = (
    CA_ACLED.groupby(['country', 'year'])
    .size()
    .reset_index(name='total_crimes')
)


bar_chart = alt.Chart(aggregated_data).mark_bar().encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('total_crimes:Q', title='Total Crimes'),
    color=alt.Color('country:N', title='Country'),
    tooltip=['country', 'year', 'total_crimes']
).properties(
    title="Total Crimes Per Year Per Country",
    width=600,
    height=400
)

bar_chart.show()
```

## Line Chart for Crimes
```{python}

line_chart = alt.Chart(aggregated_data).mark_line(point=True).encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('total_crimes:Q', title='Total Crimes'),
    color=alt.Color('country:N', title='Country'),
    tooltip=['country', 'year', 'total_crimes']
).properties(
    title="Total Crimes Per Year Per Country",
    width=600,
    height=400
)


line_chart.show()
```

## Lets rerun with Violent Crimes per Person

```{python}
wbdi = pd.read_csv('/Users/willsigal/Desktop/UChicago/Fall 2025/Python Final/Clean Data /world_bank_development_indicators_cleaned.csv')

wbdi['year'] = pd.to_datetime(wbdi['date']).dt.year

wbdi = wbdi.rename(columns={'population': 'Population'})


merged_data = pd.merge(aggregated_data, wbdi[['country', 'year', 'Population']],
                       on=['country', 'year'], 
                       how='left')


merged_data['crimes_per_person'] = merged_data['total_crimes'] / merged_data['Population']




line_chart = alt.Chart(merged_data).mark_line(point=True).encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('crimes_per_person:Q', title='Crimes per Person'),
    color=alt.Color('country:N', title='Country'),
    tooltip=['country', 'year', 'crimes_per_person']
).properties(
    title="Crimes Per Person Per Year Per Country",
    width=400,
    height=400
)

# Display the chart
line_chart.show()
```

```{python}
wbdi.columns
```

## VS Line of only crimes in wbdi
```{python}
wbdi['homicide_per_person'] = wbdi['intentional_homicides'] / wbdi['Population']

line_chart_wbdi = alt.Chart(wbdi).mark_line(point=True).encode(
    x=alt.X('date:T', title = 'Year'),
    y=alt.Y('homicide_per_person:Q', title= 'Homicide Per Person'),
    color=alt.Color('country:N', title= 'Country'),
    tooltip=['country', 'date', 'homicide_per_person']
).properties(
    title="Crimes Per Person Per Year Per Country",
    width=400,
    height=400
)

line_chart_wbdi

```

```{python}
# Filter data for El Salvador
el_salvador_data = CA_ACLED[CA_ACLED['country'] == 'El Salvador']

# Aggregate data to get total crimes per year by event type
crime_type_data = (
    el_salvador_data.groupby(['year', 'event_type'])
    .size()
    .reset_index(name='crime_count')
)

# Create the stacked bar chart
stacked_bar_chart = alt.Chart(crime_type_data).mark_bar().encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('crime_count:Q', title='Number of Crimes'),
    color=alt.Color('event_type:N', title='Crime Type'),
    tooltip=['year', 'event_type', 'crime_count']
).properties(
    title="Crimes Per Year by Type in El Salvador",
    width=600,
    height=400
)

# Display the chart
stacked_bar_chart.show()
```

## Analyzing a different ACLED DataSet
```{python}
acled_2013 = pd.read_csv('/Users/willsigal/Desktop/UChicago/Fall 2025/Python Final/2013-01-01-2024-01-01-Central_America.csv')
```


```{python}
missing_columns = [col for col in CA_ACLED.columns if col not in acled_2013.columns]

print("Columns in df2 but not in df1:", missing_columns)
```


```{python}
print(acled_2013.columns)

print(CA_ACLED.columns)
```


```{python}
el_salvador_data_2 = acled_2013[acled_2013['country'] == 'El Salvador']

crime_event_type_subtype_data = (
    el_salvador_data.groupby(['year', 'event_type', 'sub_event_type'])
    .size()
    .reset_index(name='count_event_count')
)
```

```{python}
# Create the bar chart
bar_chart_crime = alt.Chart(crime_event_type_subtype_data).mark_bar().encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('count_event_count:Q', title='Total Crimes'),
    color=alt.Color('event_type', title='Crime Type'),
    tooltip=['count_event_count', 'year', 'event_type']
).properties(
    title="Total Crimes in El Salvador: Per Year Per Type",
    width=600,
    height=400
)

# Display the chart
bar_chart_crime.show()
```


```{python}
# Create the bar chart
bar_chart_crime = alt.Chart(crime_event_type_subtype_data).mark_bar().encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('count_event_count:Q', title='Total Crimes'),
    color=alt.Color('sub_event_type', title='Crime Sub-Type'),
    tooltip=['count_event_count', 'year', 'sub_event_type']
).properties(
    title="Total Crimes in El Salvador: Per Year Per Sub-Type",
    width=600,
    height=400
)

# Display the chart
bar_chart_crime.show()
```


```{python}
pie_charts = []

# Loop through each unique year and create a pie chart
for year in crime_event_type_subtype_data['year'].unique():
    year_data = crime_event_type_subtype_data[crime_event_type_subtype_data['year'] == year]
    
    pie_chart = alt.Chart(year_data).mark_arc().encode(
        theta=alt.Theta(field="count_event_count", type="quantitative"),
        color=alt.Color(field="sub_event_type", type="nominal", legend=alt.Legend(title="Sub Event Type")),
        tooltip=[
            alt.Tooltip("event_type:N", title="Event Type"),
            alt.Tooltip("sub_event_type:N", title="Sub Event Type"),
            alt.Tooltip("count_event_count:Q", title="Event Count")
        ]
    ).properties(
        title=f"Crime Event Distribution in El Salvador ({year})"
    )
    
    pie_charts.append(pie_chart)

# Display all pie charts
alt.vconcat(*pie_charts)
```

## Now Lets Look at Actors in El Salvador
```{python}
actors_df = (el_salvador_data_2.groupby(['year', 'actor1'])
    .size()
    .reset_index(name='count_actors')
)

unique_actors = actors_df['actor1'].nunique()
```

```{python}
print(f"Total unique actors: {unique_actors}")

## Too many actors

actor_counts = (
    el_salvador_data_2.groupby('actor1')
    .size()
    .reset_index(name='total_count')
    .sort_values(by='total_count', ascending=False)
)

## Lets filter out actors that appear less than 10 times through the years:

threshold = 10 
actor_counts['cleaned_actor1'] = actor_counts['actor1'].where(
    actor_counts['total_count'] >= threshold, 'Other'
)

cleaned_actor_counts = (
    actor_counts.groupby('cleaned_actor1')['total_count']
    .sum()
    .reset_index()
    .sort_values(by='total_count', ascending=False)
)

print(cleaned_actor_counts)
```


## Lets Clean it up a little More

```{python}
actor_mapping = {
    'Police Forces of El Salvador (2019-)': 'Police Forces of El Salvador',
    'Police Forces of El Salvador (2009-2019)': 'Police Forces of El Salvador',
    'Military Forces of El Salvador (2019-)': 'Military Forces of El Salvador',
    'Military Forces of El Salvador (2009-2019)': 'Military Forces of El Salvador',
    'B-18 (S): Barrio-18 (Surenos)': 'B-18: Barrio-18',
    'B-18 (R): Barrio-18 (Revolucionarios)': 'B-18: Barrio-18',
    'Unidentified Gang (El Salvador)': 'Unidentified Group (El Salvador)',
    'Unidentified Armed Group (El Salvador)': 'Unidentified Group (El Salvador)'
}

#Apply the mapping to the `actor1` column
actors_df['cleaned_actor1'] = actors_df['actor1'].replace(actor_mapping)

#group by categories
tidy_actor_counts = (
    actors_df.groupby('cleaned_actor1')['count_actors']
    .sum()
    .reset_index()
    .sort_values(by='count_actors', ascending=False)
)

# Display the tidy result
print(f"Total unique actors after cleaning: {tidy_actor_counts['cleaned_actor1'].nunique()}")
print(tidy_actor_counts)
```

## applying it to the main dataset of el salvador to track actors year by year
```{python}
el_salvador_data_2['cleaned_actor1'] = el_salvador_data_2['actor1'].replace(actor_mapping)

# Group by year and cleaned actor categories, then count occurrences
yearly_actor_counts = (
    el_salvador_data_2.groupby(['year', 'cleaned_actor1'])
    .size()
    .reset_index(name='count_actors')
)

```


```{python}
bar_chart_crime = alt.Chart(yearly_actor_counts).mark_bar().encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('count_actors:Q', title='Actor Count'),
    color=alt.Color('cleaned_actor1', title='Actor'),
    tooltip=['cleaned_actor1', 'year', 'count_actors']
).transform_filter(
    alt.datum.count_actors > 20  # Filter for actors with count > 20
).properties(
    title="Actor Prevalence by Year (Count > 20)",
    width=600,
    height=400
)

# Display the chart
bar_chart_crime.show()
```


## Topic Modeling


```{python}
import gensim
from gensim import corpora
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
import re
import altair as alt
import pandas as pd


el_salvador_filtered = acled_2013[acled_2013['country'] == 'El Salvador']

## Preprocess
def preprocess_text_column(text):
    text = text.lower()
    text = re.sub(r'\W+', ' ', text)
    tokens = text.split()
    tokens = [word for word in tokens if word not in ENGLISH_STOP_WORDS and len(word) > 3] 
    return tokens


el_salvador_filtered['notes_cleaned'] = el_salvador_filtered['notes'].apply(
    lambda x: preprocess_text_column(x) if isinstance(x, str) else []
)

#Build the dictionary/ corpus
lda_dictionary = corpora.Dictionary(el_salvador_filtered['notes_cleaned'])
lda_corpus = [lda_dictionary.doc2bow(text) for text in el_salvador_filtered['notes_cleaned']]

# Train LDA model on all years
lda_model = gensim.models.LdaModel(
    lda_corpus, 
    num_topics=5,  # Adjust as needed
    id2word=lda_dictionary, 
    passes=15
)

# Get the top words for each topic
def get_topic_top_words(lda_model, num_words=5):
    topics = lda_model.print_topics(num_topics=-1, num_words=num_words)
    topic_dict = {
        topic_id: [word.split("*")[1].strip('"') for word in topic_desc.split(" + ")]
        for topic_id, topic_desc in topics
    }
    return topic_dict

topic_words = get_topic_top_words(lda_model, num_words=5)

# Convert topics to a DataFrame for tabular display
topic_words_table = pd.DataFrame([
    {"Topic": topic_id, "Words": ", ".join(words)}
    for topic_id, words in topic_words.items()
])


def calculate_topic_distribution(document):
    topic_distribution = lda_model.get_document_topics(document, minimum_probability=0.0)
    return [prob for _, prob in topic_distribution]

el_salvador_filtered['topic_distribution'] = el_salvador_filtered['notes_cleaned'].apply(
    lambda x: calculate_topic_distribution(lda_dictionary.doc2bow(x))
)

# Reset index to ensure alignment
el_salvador_filtered = el_salvador_filtered.reset_index(drop=True)

# Create DataFrame from topic distributions
topic_columns = [f"Topic {i}" for i in range(lda_model.num_topics)]
topic_distributions_df = pd.DataFrame(
    el_salvador_filtered['topic_distribution'].tolist(), 
    columns=topic_columns
)

#concat back into df
el_salvador_filtered = pd.concat([el_salvador_filtered, topic_distributions_df], axis=1)

#aggregate topic proportions by year
topics_over_time = el_salvador_filtered.groupby('year')[topic_columns].mean().reset_index()

#visualize topic proportions over time
topics_melted = topics_over_time.melt(id_vars='year', var_name='Topic', value_name='Proportion')

topic_chart = alt.Chart(topics_melted).mark_line(point=True).encode(
    x='year:O',
    y='Proportion:Q',
    color='Topic:N',
    tooltip=['year', 'Topic', 'Proportion']
).properties(
    title="Topic Proportions Over Time",
    width=600,
    height=400
)

topic_chart.show()
```

```{python}
print(topic_words_table)
```


```{python}
from collections import Counter

#  word frequencies for each year
def get_word_frequencies_by_year(df):
    word_frequencies = {}
    for year, group in df.groupby('year'):
        all_words = [word for text in group['notes_cleaned'] for word in text]
        word_counts = Counter(all_words)
        word_frequencies[year] = word_counts
    return word_frequencies


word_frequencies_by_year = get_word_frequencies_by_year(el_salvador_filtered)

# Convert to DF
word_freq_df = pd.DataFrame([
    {"Year": year, "Word": word, "Frequency": freq}
    for year, word_counts in word_frequencies_by_year.items()
    for word, freq in word_counts.items()
])


top_words_df = (
    word_freq_df.groupby("Year")
    .apply(lambda group: group.nlargest(10, "Frequency"))
    .reset_index(drop=True)
)


alt.Chart(top_words_df).mark_bar().encode(
    x=alt.X("Frequency:Q", title="Frequency"),
    y=alt.Y("Word:N", title="Word", sort="-x"),
    color="Year:N",
    column=alt.Column("Year:O", title="Year")
).properties(
    title="Top Words by Year",
    width=150,
    height=400
)




```


```{python}
 
```